{"cells":[{"cell_type":"markdown","metadata":{"id":"LAbzXC1IPEo0"},"source":["# Import libraries."]},{"cell_type":"code","execution_count":null,"metadata":{"id":"VAA25QU4etGg"},"outputs":[],"source":["import torch\n","import pandas\n","import numpy as np\n","from sklearn.model_selection import ShuffleSplit\n","from sklearn.model_selection import KFold\n","from statistics import mode\n","import statistics"]},{"cell_type":"markdown","metadata":{"id":"RxAY-7D4PQhn"},"source":["# Load the dataset."]},{"cell_type":"markdown","metadata":{"id":"wyFIFkB0Q2qB"},"source":["The following step is just to test that csv file is loading correctly."]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":175},"executionInfo":{"elapsed":26,"status":"ok","timestamp":1650837446312,"user":{"displayName":"Ana Cristina Soto Rojas","userId":"13726317083160294307"},"user_tz":360},"id":"oBSYJrmzGk8Y","outputId":"d21f1acd-56be-494d-d655-95ea9e9b5be6"},"outputs":[{"data":{"text/html":["\n","  <div id=\"df-4cfb0755-fc98-4b07-a38b-039506b565e0\">\n","    <div class=\"colab-df-container\">\n","      <div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>Price</th>\n","      <th>Size</th>\n","      <th>Rooms</th>\n","      <th>Toilets</th>\n","      <th>Parking</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>10000000</td>\n","      <td>343</td>\n","      <td>4</td>\n","      <td>7</td>\n","      <td>5</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>9979947</td>\n","      <td>343</td>\n","      <td>4</td>\n","      <td>6</td>\n","      <td>5</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>8500000</td>\n","      <td>420</td>\n","      <td>4</td>\n","      <td>6</td>\n","      <td>4</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>8039200</td>\n","      <td>278</td>\n","      <td>4</td>\n","      <td>7</td>\n","      <td>4</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>\n","      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-4cfb0755-fc98-4b07-a38b-039506b565e0')\"\n","              title=\"Convert this dataframe to an interactive table.\"\n","              style=\"display:none;\">\n","        \n","  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n","       width=\"24px\">\n","    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n","    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n","  </svg>\n","      </button>\n","      \n","  <style>\n","    .colab-df-container {\n","      display:flex;\n","      flex-wrap:wrap;\n","      gap: 12px;\n","    }\n","\n","    .colab-df-convert {\n","      background-color: #E8F0FE;\n","      border: none;\n","      border-radius: 50%;\n","      cursor: pointer;\n","      display: none;\n","      fill: #1967D2;\n","      height: 32px;\n","      padding: 0 0 0 0;\n","      width: 32px;\n","    }\n","\n","    .colab-df-convert:hover {\n","      background-color: #E2EBFA;\n","      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n","      fill: #174EA6;\n","    }\n","\n","    [theme=dark] .colab-df-convert {\n","      background-color: #3B4455;\n","      fill: #D2E3FC;\n","    }\n","\n","    [theme=dark] .colab-df-convert:hover {\n","      background-color: #434B5C;\n","      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n","      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n","      fill: #FFFFFF;\n","    }\n","  </style>\n","\n","      <script>\n","        const buttonEl =\n","          document.querySelector('#df-4cfb0755-fc98-4b07-a38b-039506b565e0 button.colab-df-convert');\n","        buttonEl.style.display =\n","          google.colab.kernel.accessAllowed ? 'block' : 'none';\n","\n","        async function convertToInteractive(key) {\n","          const element = document.querySelector('#df-4cfb0755-fc98-4b07-a38b-039506b565e0');\n","          const dataTable =\n","            await google.colab.kernel.invokeFunction('convertToInteractive',\n","                                                     [key], {});\n","          if (!dataTable) return;\n","\n","          const docLinkHtml = 'Like what you see? Visit the ' +\n","            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n","            + ' to learn more about interactive tables.';\n","          element.innerHTML = '';\n","          dataTable['output_type'] = 'display_data';\n","          await google.colab.output.renderOutput(dataTable, element);\n","          const docLink = document.createElement('div');\n","          docLink.innerHTML = docLinkHtml;\n","          element.appendChild(docLink);\n","        }\n","      </script>\n","    </div>\n","  </div>\n","  "],"text/plain":["      Price  Size  Rooms  Toilets  Parking\n","0  10000000   343      4        7        5\n","1   9979947   343      4        6        5\n","2   8500000   420      4        6        4\n","3   8039200   278      4        7        4"]},"execution_count":2,"metadata":{},"output_type":"execute_result"}],"source":["dataset_torch = pandas.read_csv('sao-paulo-properties-april-2019.csv', usecols = [\"Rooms\", \"Size\", \"Toilets\", \"Parking\", \"Price\"])\n","dataset_torch.head(4)"]},{"cell_type":"markdown","metadata":{"id":"hNYyAgTmROtL"},"source":["## Preprocessing the data."]},{"cell_type":"markdown","metadata":{"id":"Szkq3GDV8vHN"},"source":["The dataset can be found in the following url: https://www.kaggle.com/yashsawarn/wifi-stretgth-for-rooms. We are using for this example a couple of atributes from this file, such as: ``Rooms, Size, Toilets and Parking``."]},{"cell_type":"code","execution_count":null,"metadata":{"id":"dV9bHQspetGi"},"outputs":[],"source":["\n","# read_dataset: \n","# Read a csv file and returns a pytorch tensor.\n","def read_dataset(csv_name = 'sao-paulo-properties-april-2019.csv'):\n","\n","    # Filter with columns are we gonna used from the original csv dataset.\n","    dataset_torch = pandas.read_csv(csv_name, usecols = [\"Rooms\", \"Size\", \"Toilets\", \"Parking\", \"Price\"])\n","    # Create a new column with the results of apply 3 conditions to the Price value.\n","    conditions = [\n","      (dataset_torch[\"Price\"] > 900000 ),\n","      (dataset_torch[\"Price\"] > 580000) & (dataset_torch[\"Price\"] <= 900000),\n","      (dataset_torch[\"Price\"] > 400000) & (dataset_torch[\"Price\"] <= 580000),\n","      (dataset_torch[\"Price\"] <= 400000)\n","    ]\n","    # Label for eache category described before.\n","    values = [4,3,2,1]\n","    dataset_torch[\"Category\"] = np.select(conditions, values)\n","    dataset_torch = dataset_torch.drop(columns = [\"Price\"])\n","    \n","    # Return the generated dataframe in torch format.\n","    return torch.from_numpy(dataset_torch.values)"]},{"cell_type":"markdown","metadata":{"id":"9tNOQE8dWK5j"},"source":["In this step we load the data doing a call to the `read_dataset` function."]},{"cell_type":"code","execution_count":null,"metadata":{"id":"LZ2_0pmLk7x6"},"outputs":[],"source":["dataset_torch = read_dataset()"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":8,"status":"ok","timestamp":1650837446543,"user":{"displayName":"Ana Cristina Soto Rojas","userId":"13726317083160294307"},"user_tz":360},"id":"G92NetKUOAhc","outputId":"237ff284-ca28-4c00-b247-35331f8afe6d"},"outputs":[{"name":"stdout","output_type":"stream","text":["tensor([1, 2, 3, 4])\n","tensor([1913,  998,  998,  985])\n"]}],"source":["categorias, total_obs = dataset_torch[:,4].unique(dim = 0, return_counts = True)\n","print(categorias)\n","print(total_obs)"]},{"cell_type":"markdown","metadata":{"id":"JtjKVb7kcvRM"},"source":["# Create the class Node_CART to genere each node to build a tree."]},{"cell_type":"code","execution_count":null,"metadata":{"id":"wJ83JR2NcuHb"},"outputs":[],"source":["class Node_CART:    \n","    def __init__(self, num_classes = 4, ref_CART = None, current_depth = 0):\n","        \"\"\"\n","        Create the node attributes  \n","        param num_classes: K number of classes to classify param ref_cart: reference to the tree containing the node\n","        param current_depth: current depth of the node in the tree\n","        \"\"\"\n","        self.ref_CART = ref_CART\n","        self.threshold_value = 0\n","        self.feature_num = 0\n","        self.node_right = None\n","        self.node_left = None\n","        self.data_torch_partition = None\n","        self.gini = 0\n","        self.dominant_class = None\n","        self.accuracy_dominant_class = None        \n","        self.num_classes = num_classes\n","        self.current_depth = current_depth\n","    \n","    #  Recursive function to write the node content to an xml formatted string param current_str : the xml content so far in the whole tree return the string with the node content\n","    def to_xml(self, current_str = \"\"):\n","        str_node = \"<node><thresh>\" + str(self.threshold_value) + \"</thresh>\" + \"<feature>\" + str(self.feature_num) + \"</feature><depth>\" + str(self.current_depth)+ \"</depth>\" \n","        str_node += \"<gini>\" + str(self.gini) + \"</gini>\"\n","        if(self.node_right != None):\n","            str_left = self.node_right.to_xml(current_str)\n","            str_node += str_left\n","        if(self.node_left != None):\n","            str_right = self.node_left.to_xml(current_str)\n","            str_node += str_right\n","            \n","        if(self.is_leaf()):\n","            str_node += \"<dominant_class>\" + str(self.dominant_class) + \"</dominant_class><acc_dominant_class>\"  + str(self.accuracy_dominant_class) + \"</acc_dominant_class>\"\n","        str_node += \"</node>\"\n","        return str_node\n","    \n","    # Checks whether the node is a leaf\n","    def is_leaf(self):\n","        return (self.node_left == None and self.node_right == None)\n","    \n","    \n","    def create_with_children(self, data_torch, current_depth, list_selected_features = [], min_gini = 0.000001):\n","        \"\"\"\n","        Creates a node by selecting the best feature and threshold, and if needed, creating its children\n","        param data_torch: dataset with the current partition to deal with in the node\n","        param current_depth: depth counter for the node\n","        param list_selected_features: list of selected features so far for the CART building process\n","        param min_gini: hyperparmeter selected by the user defining the minimum tolerated gini coefficient for a  node\n","        return the list of selected features so far\n","        \"\"\"        \n","        #update depth of children\n","        depth_children = current_depth + 1\n","        if(depth_children <= self.ref_CART.get_max_depth()):\n","\n","            num_observations = data_torch.shape[0]            \n","            # careful with max depth\n","            #if no threshold and feature were selected, select it using a greedy approach            \n","            (threshold_value, feature_num, gini) = self.select_best_feature_and_thresh(data_torch, list_features_selected = list_selected_features)\n","            list_selected_features += [feature_num]\n","            #store important data in attributes\n","            self.threshold_value = threshold_value\n","            self.feature_num = feature_num\n","            self.data_torch_partition = data_torch\n","            self.gini = gini            \n","            num_features = data_torch.shape[1]\n","            #data_torch_left = torch.zeros(1, num_features)\n","            #data_torch_right = torch.zeros(1, num_features)\n","            #create the right and left node data if the current gini is still high            \n","            if(self.gini > min_gini):                \n","                data_torch_left = data_torch[data_torch[:, feature_num] < threshold_value]\n","                data_torch_right = data_torch[data_torch[:, feature_num] >= threshold_value]\n","                #if the new partitions have more than min_observations, make them\n","                if(data_torch_left.shape[0] >= self.ref_CART.get_min_observations() and data_torch_right.shape[0] >= self.ref_CART.get_min_observations()):\n","                    #add data to the right and left children\n","                    self.node_right = Node_CART(num_classes = self.num_classes, ref_CART = self.ref_CART, current_depth = depth_children)\n","                    self.node_left = Node_CART(num_classes = self.num_classes, ref_CART = self.ref_CART, current_depth = depth_children)\n","                    list_selected_features = self.node_right.create_with_children(data_torch_right, depth_children, list_selected_features = list_selected_features)            \n","                    self.node_left.create_with_children( data_torch_left, depth_children, list_selected_features = list_selected_features)\n","        #if is leaf, fill the         \n","        if(self.is_leaf()):            \n","            labels_data = data_torch[:,  -1]\n","            self.dominant_class = torch.mode(labels_data).values.item()\n","            num_obs_label = labels_data[labels_data == self.dominant_class].shape[0]\n","            self.accuracy_dominant_class = num_obs_label / labels_data.shape[0]           \n","            \n","        return list_selected_features\n","\n","\n","    def calculate_gini(self, data_partition_torch, num_classes = 4):\n","        \"\"\"\n","        Calculates the gini coefficient for a given partition with the given number of classes\n","        param data_partition_torch: current dataset partition as a tensor\n","        param num_classes: K number of classes to discriminate from\n","        returns the calculated gini coefficient\n","        \"\"\"\n","        #TODO\n","        n = data_partition_torch.size()[0] \n","        if(n != 0):\n","            categorias, total_obs = data_partition_torch[:,4].unique(dim = 0, return_counts = True)\n","            suma = sum((total_obs/n)**2)\n","            gini = 1 - suma\n","        else:\n","            gini = 1\n","        return gini\n","      \n","    def calculate_rss(self, data_partition_torch):\n","        \"\"\"\n","        Calculates the Residual Sum of Squares (RSS)\n","        param data_partition_torch: current dataset partition as a tensor\n","        returns the calculated RSS\n","        \"\"\"\n","        rss = (data_partition_torch - torch.mean(data_partition_torch))**2\n","        rss = torch.sum(rss)\n","        return rss\n","\n","\n","         \n","    def select_best_feature_and_thresh(self, data_torch, list_features_selected = [], num_classes = 4):\n","        \"\"\"\n","        ONLY USE  2 FORS\n","        Selects the best feature and threshold that minimizes the gini coefficient\n","        param data_torch: dataset partition to analyze\n","        param list_features_selected list of features selected so far, thus must be ignored \n","        param num_classes: number of K classes to discriminate from \n","        return min_thresh, min_feature, min_gini found for the dataset partition when \n","        selecting the found feature and threshold\n","        \"\"\"     \n","          \n","        n,n_i,n_d = 0,0,0\n","        min_thresh = -1\n","        min_feature = -1\n","        min_gini = 10\n","\n","        for i in range(data_torch.size()[1]-1):\n","          data_feature = data_torch[:, i].unsqueeze(1)\n","          unique_values = torch.unique(data_torch[:,i], sorted  = True)\n","          n = data_torch.size()[0]\n","\n","          for j in unique_values:\n","              D_izq = data_torch[data_torch[:,i] < j.item()]\n","              D_der = data_torch[data_torch[:,i] >= j.item()]\n","              n_i = D_izq.size()[0]\n","              n_d = D_der.size()[0]\n","              #rss = self.calculate_rss(D_izq) + self.calculate_rss(D_der)\n","              coef_gini = (n_i/n)*self.calculate_gini(D_izq) + (n_d/n)*self.calculate_gini(D_der)\n","              if(coef_gini < min_gini):\n","                  min_gini = coef_gini\n","                  min_feature = i\n","                  min_thresh = j.item()        \n","        # print(min_thresh, min_feature, min_gini)     \n","        return (min_thresh, min_feature, min_gini)  \n","           \n","    \n","    def evaluate_node(self, input_torch): \n","        \"\"\"\n","        Evaluates an input observation within the node. \n","        If is not a leaf node, send it to the corresponding node\n","        return predicted label\n","        \"\"\"\n","        feature_val_input = input_torch[self.feature_num]\n","        if(self.is_leaf()):\n","            return self.dominant_class\n","        else:\n","            if(feature_val_input < self.threshold_value):\n","                return self.node_left.evaluate_node(input_torch)\n","            else:\n","                return self.node_right.evaluate_node(input_torch)"]},{"cell_type":"markdown","metadata":{"id":"9o3Xym5Ac6C7"},"source":["# Create the class CART who contains the root node of the tree."]},{"cell_type":"code","execution_count":null,"metadata":{"id":"dRlk9lVKc_Ri"},"outputs":[],"source":["# This class only contents the root node.\n","class CART:\n","    def __init__(self, dataset_torch, max_CART_depth = 4, min_observations = 2):\n","        # min observations per node\n","        self.min_observations = min_observations\n","        # Create a new root node to create the tree.\n","        self.root = Node_CART(num_classes = 4, ref_CART = self, current_depth = 0)\n","        self.max_CART_depth = max_CART_depth\n","        self.list_selected_features = []\n","    \n","    # Gets the root node of the tree.\n","    def get_root(self):     \n","        return self.root\n","    \n","    # Returns the min of observations per node.\n","    def get_min_observations(self): \n","        return self.min_observations\n","    \n","    # Get the max depth of the tree.\n","    def get_max_depth(self):    \n","        return self.max_CART_depth\n","    \n","    # Buiild a CART tree from root.\n","    def build_CART(self, data_torch):\n","        self.list_selected_features = self.root.create_with_children(data_torch, current_depth = 0)\n","    \n","    # Write a XML file with the tree content.\n","    def to_xml(self, xml_file_name): \n","        str_nodes = self.root.to_xml()\n","        file = open(xml_file_name,\"w+\") \n","        file.write(str_nodes)\n","        file.close()\n","        return str_nodes\n","    \n","    # Evaluate a specifc input in the tree and get the predicted class.\n","    def evaluate_input(self, input_torch):\n","        \"\"\"\n","        Evaluate a specific input in the tree and get the predicted class\n","        \"\"\"\n","        return self.root.evaluate_node(input_torch)"]},{"cell_type":"markdown","metadata":{"id":"JSJX60-2dLw-"},"source":["# Create the class Train_CART who create a whole tree structure."]},{"cell_type":"code","execution_count":null,"metadata":{"id":"Sm47O_m8dYni"},"outputs":[],"source":["# Use to generate a whole tree structure of a CART model.    \n","def train_CART(dataset_torch, name_xml = \"\", max_CART_depth = 3, min_obs_per_leaf = 2): \n","    # Create an element from CART class.\n","    tree = CART(dataset_torch = dataset_torch, max_CART_depth = max_CART_depth, min_observations =  min_obs_per_leaf)\n","    # Generate the children for the tree.\n","    tree.build_CART(dataset_torch)\n","    # Call to generate a XML file with tree content.\n","    if(not name_xml == \"\"):\n","        tree.to_xml(name_xml)\n","\n","    # Return the tree created.\n","    return tree"]},{"cell_type":"markdown","metadata":{"id":"pkS9WbozeDqw"},"source":["# Evaluate a CART tree."]},{"cell_type":"code","execution_count":null,"metadata":{"id":"SHdBI6mBeIJ2"},"outputs":[],"source":["# Test a previously built CART tree.\n","def test_CART(tree, testset_torch):\n","    sum  = 0\n","    for i in range(testset_torch.size()[0]):\n","        result = tree.evaluate_input(testset_torch[i])\n","        if testset_torch[i][4] == result:\n","            sum +=1\n","    accuracy = sum / testset_torch.size()[0] * 100;\n","    return accuracy"]},{"cell_type":"markdown","metadata":{"id":"3umi_HuljYgr"},"source":["# Partition Validation"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"9TW8AWWPjd3R"},"outputs":[],"source":["def partition_validation(dataset_torch, max_CART_depth, num_splits):\n","    rs = ShuffleSplit(n_splits = num_splits, test_size=.30)\n","    cont_part = 1\n","    results = []\n","    for train_index, test_index in rs.split(dataset_torch):\n","        print(\"Evaluación de la partion %s:\" % (cont_part))\n","        train = dataset_torch[train_index]\n","        test = dataset_torch[test_index]\n","        # Train a new tree for a specific dataset.\n","        tree = train_CART(train, max_CART_depth = max_CART_depth, name_xml = \"CART_example.xml\")\n","        # Test the CART model.\n","        acc = test_CART(tree, test)\n","        print(\"Acc: %s\" % (acc))\n","        cont_part +=1  \n","        results.append(acc)\n","    return(results)    \n","        "]},{"cell_type":"markdown","metadata":{"id":"cbvYpZIPeK42"},"source":["# Evaluation CART"]},{"cell_type":"markdown","metadata":{"id":"_2hZ9UDttzC7"},"source":["### Evaluation CART with depth 2."]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":11842,"status":"ok","timestamp":1650837459406,"user":{"displayName":"Ana Cristina Soto Rojas","userId":"13726317083160294307"},"user_tz":360},"id":"cQCSEAcrtj7M","outputId":"e133624e-350f-48d1-a410-86c8a66bbd8a"},"outputs":[{"name":"stdout","output_type":"stream","text":["65.10012259910094\n"]}],"source":["# Train a new tree for a specific dataset.\n","tree = train_CART(dataset_torch, max_CART_depth = 2, name_xml = \"CART_example.xml\")\n","# Test the CART model.\n","acc = test_CART(tree, dataset_torch)\n","print(acc)  "]},{"cell_type":"markdown","metadata":{"id":"k6ssqnb8uFhc"},"source":["### Evaluation CART with depth 3."]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":5837,"status":"ok","timestamp":1650837465236,"user":{"displayName":"Ana Cristina Soto Rojas","userId":"13726317083160294307"},"user_tz":360},"id":"vo3krqBmt4I5","outputId":"27f68186-4b07-4877-da72-1f803bfd9222"},"outputs":[{"name":"stdout","output_type":"stream","text":["65.8152840212505\n"]}],"source":["# Train a new tree for a specific dataset.\n","tree = train_CART(dataset_torch, max_CART_depth = 3, name_xml = \"CART_example.xml\")\n","# Test the CART model.\n","acc = test_CART(tree, dataset_torch)\n","print(acc)  "]},{"cell_type":"markdown","metadata":{"id":"blFC8TrFua8K"},"source":["# Evaluation CART random partitions"]},{"cell_type":"markdown","metadata":{"id":"IWAQubzGuem3"},"source":["### Evaluation with depth 2"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":41824,"status":"ok","timestamp":1650837507048,"user":{"displayName":"Ana Cristina Soto Rojas","userId":"13726317083160294307"},"user_tz":360},"id":"30efE9IIuIg3","outputId":"128ff635-7ed2-4ff8-8392-4e423f0c1a25"},"outputs":[{"name":"stdout","output_type":"stream","text":["Evaluación de la partion 1:\n","Acc: 63.444520081688225\n","Evaluación de la partion 2:\n","Acc: 64.0571817562968\n","Evaluación de la partion 3:\n","Acc: 64.32947583390062\n","Evaluación de la partion 4:\n","Acc: 63.30837304288631\n","Evaluación de la partion 5:\n","Acc: 63.98910823689585\n","Evaluación de la partion 6:\n","Acc: 63.58066712049013\n","Evaluación de la partion 7:\n","Acc: 64.60176991150442\n","Evaluación de la partion 8:\n","Acc: 66.3716814159292\n","Evaluación de la partion 9:\n","Acc: 65.14635806671205\n","Evaluación de la partion 10:\n","Acc: 65.48672566371681\n","\n","Mean:\t64.43158611300204\n","STD:\t0.9845197708153681\n"]}],"source":["results = partition_validation(dataset_torch, 2, 10)\n","print(\"\\nMean:\\t\" + str(statistics.mean(results)))\n","print(\"STD:\\t\" + str(statistics.stdev(results)))"]},{"cell_type":"markdown","metadata":{"id":"tp5G1nYWvgJH"},"source":["### Evaluation with depth 3"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":38343,"status":"ok","timestamp":1650840114186,"user":{"displayName":"Ana Cristina Soto Rojas","userId":"13726317083160294307"},"user_tz":360},"id":"tdo1q2Urut8E","outputId":"04a9f862-5816-49a2-c6cc-6020b671bfc0"},"outputs":[{"name":"stdout","output_type":"stream","text":["Evaluación de la partion 1:\n","Acc: 64.39754935330157\n","Evaluación de la partion 2:\n","Acc: 63.30837304288631\n","Evaluación de la partion 3:\n","Acc: 65.28250510551395\n","Evaluación de la partion 4:\n","Acc: 64.80599046970728\n","Evaluación de la partion 5:\n","Acc: 64.60176991150442\n","Evaluación de la partion 6:\n","Acc: 64.73791695030633\n","Evaluación de la partion 7:\n","Acc: 61.81075561606535\n","Evaluación de la partion 8:\n","Acc: 64.32947583390062\n","Evaluación de la partion 9:\n","Acc: 65.14635806671205\n","Evaluación de la partion 10:\n","Acc: 63.78488767869299\n","\n","Mean:\t64.22055820285908\n","STD:\t1.0334826767408063\n"]}],"source":["results = partition_validation(dataset_torch, 3, 10)\n","print(\"\\nMean:\\t\" + str(statistics.mean(results)))\n","print(\"STD:\\t\" + str(statistics.stdev(results)))"]},{"cell_type":"markdown","metadata":{"id":"pVYgnm4-2JCg"},"source":["# Implementation of Random Forest"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"UtE76V-Z2MkH"},"outputs":[],"source":["# Class to generate a random forest.\n","class RandomForest:\n","    def __init__(self, quantity_trees, depth):\n","        self.quantity_trees = quantity_trees\n","        self.depth = depth\n","        self.trees = []\n","    \n","    # Create K partition to train each of them with a CART.\n","    def train_random_forest(self, dataset_torch):\n","        # Generate k partitions from a dataset.\n","        kf = KFold(n_splits = self.quantity_trees)\n","        for train_index, test_index in kf.split(dataset_torch):\n","            test = dataset_torch[test_index]\n","            train = dataset_torch[train_index]\n","\n","            # Train a new tree with the partition.\n","            tree = train_CART(train, max_CART_depth = self.depth, name_xml = \"CART_example.xml\")\n","\n","            # Save the trees in a list.\n","            self.trees.append(tree)\n","\n","            # Evaluate the created tree.\n","            acc = test_CART(tree, dataset_torch)\n","\n","    # For a single observation calculate the estimator using vote scheme seen in classes.\n","    def evaluate_random_forest(self, input_torch):\n","        estimation = []\n","        for tree in self.trees:\n","            result = tree.evaluate_input(input_torch)\n","            estimation.append(result)\n","        \n","        # estimate = mode(estimation)\n","        estimate = max(set(estimation), key = estimation.count)\n","        return estimate\n","    \n","    # Calculate the random forest accuracy.\n","    def test_random_forest(self, testset_torch):\n","        sum  = 0\n","        for i in range(testset_torch.size()[0]):\n","            result = self.evaluate_random_forest(testset_torch[i])\n","            if testset_torch[i][4] == result:\n","                sum +=1\n","        accuracy = sum / testset_torch.size()[0] * 100;\n","        return accuracy\n","     "]},{"cell_type":"markdown","metadata":{"id":"PaaTSMZctbSX"},"source":["# Generating a new random forest."]},{"cell_type":"markdown","metadata":{"id":"Pl_W9y2GtkDD"},"source":["* A new random forest with depth = 3 and quantity of CARTs = 5.\n"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"ALCfKr_JtiY9"},"outputs":[],"source":["random_forest = RandomForest(5, 3)"]},{"cell_type":"markdown","metadata":{"id":"cRW3fK65t-f3"},"source":["* Start training."]},{"cell_type":"code","execution_count":null,"metadata":{"id":"Y7MRsHN6t8sL"},"outputs":[],"source":["random_forest.train_random_forest(dataset_torch)"]},{"cell_type":"markdown","metadata":{"id":"XghYG7K6Hds2"},"source":["* Evaluate random forest."]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":534,"status":"ok","timestamp":1650837569207,"user":{"displayName":"Ana Cristina Soto Rojas","userId":"13726317083160294307"},"user_tz":360},"id":"XXTH7RnQHhOK","outputId":"406aa771-c672-429b-9870-8ae6f99c9bee"},"outputs":[{"data":{"text/plain":["65.12055578259093"]},"execution_count":18,"metadata":{},"output_type":"execute_result"}],"source":["random_forest.test_random_forest(dataset_torch)"]},{"cell_type":"markdown","metadata":{"id":"6a0lUarHuN4P"},"source":["# Random Forest Evaluation"]},{"cell_type":"markdown","metadata":{"id":"tuaWvAwmV8yV"},"source":["* Fucntion to make 10 partition for test examples."]},{"cell_type":"code","execution_count":null,"metadata":{"id":"WAVlp56QuYcS"},"outputs":[],"source":["def RF_Validation(dataset_torch, max_CART_depth, num_splits, num_CARTs):\n","    rs = ShuffleSplit(n_splits = num_splits, test_size=.30)\n","    cont_part = 1\n","    results = []\n","    # Getting index for N different datasets.\n","    for train_index, test_index in rs.split(dataset_torch):\n","        print(\"Evaluación de la partion %s:\" % (cont_part))\n","        train = dataset_torch[train_index]\n","        test = dataset_torch[test_index]\n","\n","        # Training a new forest.\n","        random_forest = RandomForest(num_CARTs, max_CART_depth)\n","        random_forest.train_random_forest(train)\n","\n","        # Evaluation Accuracy.\n","        acc = random_forest.test_random_forest(test)\n","        print(\"Acc = %s\" % (acc))\n","        cont_part += 1\n","        results.append(acc)\n","    return results"]},{"cell_type":"markdown","metadata":{"id":"XuUZ-zodWFM9"},"source":["* Execute the fucntion."]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":151905,"status":"ok","timestamp":1650837721099,"user":{"displayName":"Ana Cristina Soto Rojas","userId":"13726317083160294307"},"user_tz":360},"id":"rDPoHKq3WHbn","outputId":"406806c7-bc94-49ae-88e9-98c0056bbac3"},"outputs":[{"name":"stdout","output_type":"stream","text":["Evaluación de la partion 1:\n","Acc = 64.19332879509871\n","Evaluación de la partion 2:\n","Acc = 66.98434309053778\n","Evaluación de la partion 3:\n","Acc = 63.852961198093936\n","Evaluación de la partion 4:\n","Acc = 64.94213750850919\n","Evaluación de la partion 5:\n","Acc = 66.3716814159292\n","Evaluación de la partion 6:\n","Acc = 65.82709326072158\n","Evaluación de la partion 7:\n","Acc = 66.30360789652825\n","Evaluación de la partion 8:\n","Acc = 65.69094622191967\n","Evaluación de la partion 9:\n","Acc = 64.60176991150442\n","Evaluación de la partion 10:\n","Acc = 63.78488767869299\n","\n","Mean:\t65.25527569775358\n","STD:\t1.1369160895028267\n"]}],"source":["results = RF_Validation(dataset_torch=dataset_torch, max_CART_depth=3, num_splits=10, num_CARTs=5)\n","print(\"\\nMean:\\t\" + str(statistics.mean(results)))\n","print(\"STD:\\t\" + str(statistics.stdev(results)))\n"]}],"metadata":{"colab":{"collapsed_sections":[],"name":"DecisionTrees_base.ipynb","provenance":[]},"kernelspec":{"display_name":"Python 3 (ipykernel)","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.9.7"}},"nbformat":4,"nbformat_minor":0}
